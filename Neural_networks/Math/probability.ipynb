{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d219bc9",
   "metadata": {},
   "source": [
    "### Probability\n",
    "\n",
    "one note in reading: ðŸ˜… the vertical line '|' in $Pr(x|y)$ is read in english as \"**Given**\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7fcc9",
   "metadata": {},
   "source": [
    "Probability is critical to deep learning. In supervised learning, deep networks implicitly rely on a probabilistic formulation of the loss function. In unsupervised learning,\n",
    "generative models aim to produce samples that are drawn from the same probability\n",
    "distribution as the training data. Reinforcement learning occurs within Markov decision\n",
    "processes, and these are defined in terms of probability distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4c505",
   "metadata": {},
   "source": [
    "**Random variable and probability distribution**:\n",
    "\n",
    "A random variable xdenotes a quantity that is uncertain. It may be discrete (take only\n",
    "certain values, for example integers) or continuous (take any value on a continuum, for\n",
    "example real numbers). If we observe several instances of a random variable x, it will\n",
    "take different values, and the relative propensity to take different values is described by\n",
    "a probability distribution Pr(x).\n",
    "For a discrete variable, this distribution associates a probability Pr(x= k) âˆˆ[0,1] with\n",
    "each potential outcome k, and the sum of these probabilities is one. For a continuous\n",
    "variable, there is a non-negative probability density Pr(x= a) â‰¥0 associated with each\n",
    "value a in the domain of x, and the **integral** of this **probability density function (PDF)** over this domain must be one. This density can be greater than one for any point a. From here on, we assume that the random variables are continuous. The ideas are exactly the same for discrete distributions but with sums replacing integrals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413e1d6",
   "metadata": {},
   "source": [
    "**Joint probability**:\n",
    "\n",
    "Consider the case where we have two random variables $x$ and $y$. The joint distribution $Pr(x,y)$ tells us about the propensity that $x$ and $y$ take particular combinations of values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fda8f",
   "metadata": {},
   "source": [
    "<img src=./images/joint_probability.png width=650>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1190069",
   "metadata": {},
   "source": [
    "**marginization**:\n",
    "\n",
    "If we know the joint distribution $Pr(x,y)$ over two variables, we can recover the marginal\n",
    "distributions $Pr(x)$ and $Pr(y)$ by integrating over the other variable:\n",
    "\n",
    "$$\\int \\text{Pr}(x, y) \\cdot dx = \\text{Pr}(y)$$\n",
    "\n",
    "$$\\int \\text{Pr}(x, y) \\cdot dy = \\text{Pr}(x)$$\n",
    "\n",
    "This process is called marginalization and has the interpretation that we are computing the distribution of one variable regardless of the value the other one took. The\n",
    "idea of marginalization extends to higher dimensions, so if we have a joint distribution $Pr(x,y,z)$, we can recover the joint distribution $Pr(x,z)$ by integrating over $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6cf693",
   "metadata": {},
   "source": [
    "**Conditional probability and likelihood**:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
