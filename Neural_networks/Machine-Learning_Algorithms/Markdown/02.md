#### Markov chain monte carlo

- Any probabilistic model that explains a part of reality
exists in a high-dimensional parameter space because it is described by high dimensional model parameters.
*Markov chain Monte Carlo (MCMC)* is a methodology of
sampling from high-dimensional parameter spaces to *approximate the posterior distribution* $p(\theta |x)$.

- A *Gaussian mixture* is a weighted sum of Gaussian probability distributions. A mixture of Gaussians consists of K Gaussian RVs scaled by mixture proportions πk that are positive and add up to 1

- A Gaussian Mixture Model (GMM) is a probabilistic model that represents a dataset as a combination of multiple Gaussian distributions. It is a soft clustering technique that generalizes the *k-means* algorithm by allowing clusters to have different shapes, sizes, and orientations. $p(x) = \sum_{k=1}^{K} \pi_k \cdot \mathcal{N}(x \mid \mu_k, \Sigma_k)$

- How to find the Gaussian mixture parameters via the *expectation-maximization (EM)* algorithm?

- With MCMC algorithms, we attempt to approximate the posterior distribution
through samples. In fact, most of the Bayesian inference is designed to efficiently
approximate the posterior distribution

- be familiar with this notation: $p(x|\theta)$, which is, by definition, the **likelihood** of data x, given the parameter $\theta$.

- Variance Definition:
    - Variance helps us quantify the spread of a dataset mathematically.
    - For a random variable  $X$  with expected value  $E[X] = \mu$ , the variance, denoted as  $\text{Var}(X)$ , is: $\text{Var}(X) = E[(X - \mu)^2]$
    - This gives us an idea of how “far” values are from the mean on average.
    - For a discrete random variable  $X$  with $PMF  p(x)$ , variance is: $\text{Var}(X) = \sum_{x} (x - \mu)^2 p(x)$
    - For a continuous random variable  $X$  with $\text{PDF}  f(x)$ , variance is: $\text{Var}(X) = \int_{-\infty}^{\infty} (x - \mu)^2 f(x) dx$
- Alternative Variance Formula:
    - A useful identity for variance is: $\text{Var}(X) = E[X^2] - (E[X])^2$
    - Proof:
        - $\text{Var}(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2] = E[X^2] - 2\mu E[X] + \mu^2$,  since $E[X] = \mu$, $\text{Var}(X) = E[X^2] - \mu^2$

- in general, We can use the Bayes rule to express the posterior distribution as proportional to the product of the likelihood and prior: $p(\theta | D) \sim p(D | \theta).p(\theta)$

- A Beta random variable is a continuous random variable that follows the Beta distribution, which is parameterized by two positive shape parameters,  $\alpha$  and  $\beta$ . The Beta distribution is defined on the interval  $[0,1]$ , making it particularly useful for modeling probabilities. The probability density function (PDF) of a Beta-distributed random variable  $X \sim \text{Beta}(\alpha, \beta)$  is: $f(x; \alpha, \beta) = \frac{x^{\alpha - 1} (1 - x)^{\beta - 1}}{B(\alpha, \beta)}$

- The mean and variance of a Beta-distributed random variable are:
    - $\mathbb{E}[X] = \frac{\alpha}{\alpha + \beta}$
    - $\text{Var}(X) = \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}$

- "conjugate to the posterior" -> the posterior can be computed in closed form by updating the prior counts with observed data.

- A *Markov chain* is a sequence of possible events, in which the probability of the current event depends *only* on the previous event. A first-order Markov chain can be written as: $p(x_1, ..., x_t) = p(x_1)p(x_2|x_1)p(x_3|x_2)...p(x_t|x_t-1) = p(x_1) \prod_{i=2}^{t}p(x_i|x_i-1)$

- page rank is a stationary distribution over the states of the Markov chain.

- A *stationary distribution* (or steady-state distribution) of a Markov chain is a probability distribution over the states that remains unchanged after applying the transition matrix

- 































