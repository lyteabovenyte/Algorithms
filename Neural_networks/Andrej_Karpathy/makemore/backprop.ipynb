{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670ff919-0216-44c9-a746-16aac54824ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc02f6b1-462c-445f-b13a-a60628c6b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the names.txt file from github\n",
    "# !wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba43f33-76d4-4c3f-b8ff-e031778aa8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f894ce-d5ec-4ad4-998c-78c4b47480a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e576cb5f-fdba-4c0d-b3bc-a645f0c48e42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28787abf-ae3c-4729-a0f4-18488fe006e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to compare manual gradiants with pytorch gradinats\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "916ad973-577b-4981-92a4-5aae76514c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60c14f5a-b705-4515-a23b-dd0f9e6b6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119edfa0-0db9-400b-870c-835ede323ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3454, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47489d3a-b361-4df5-983c-170706577fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprob through logprobs\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "cmp('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4894332c-adda-43b0-bccb-c19c54b2bc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop probs -> local derivative of log * chain rule of dlogprobs\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "cmp('probs', dprobs, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2dc7c42-2112-422a-ad86-02917db555e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89be2e08-7d3a-4dfa-9a7d-f1363b4f7371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_sum_inv   | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through count_sum_inv\n",
    "# note the broadcasting on counts_sum_inv (backprob through replication, branching through graph vis.)\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
    "cmp('count_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92235ac-bebb-4b06-a5f0-c07279dcffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through counts -> which contributes to 2 branches.\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ba230f1-81d1-434c-b395-ef2bb5f2b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum vs. counts shapes torch.Size([32, 1]) torch.Size([32, 27])\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through dcounts in second branch (so we need to add them up.)\n",
    "print('counts_sum vs. counts shapes', counts_sum.shape, counts.shape)\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "cmp('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1876b9b4-f2e8-4e94-9b12-a426cc6914c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through norm_logits\n",
    "dnorm_logits = counts * dcounts  # norm_logits.exp() * dcounts\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "264c4071-b72e-4b7d-9f52-892b95c4a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits vs. logits_maxes torch.Size([32, 27]) torch.Size([32, 1])\n",
      "dlogits_maxes   | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through dlogits\n",
    "print(\"logits vs. logits_maxes\", logits.shape, logit_maxes.shape)\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdims=True)\n",
    "cmp('dlogits_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a58665cb-ee2a-4d5f-9735-f265e5734ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# another branch of dlogits\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8fa8809-3be0-4197-aa07-c5e5e2243ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 27]) torch.Size([64, 27]) torch.Size([27])\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "db2             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through the Linear layer 2\n",
    "print(h.shape, dlogits.shape, W2.shape, b2.shape) # think through matching the shape in logits = h @ W2 + b2\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('db2', db2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4146895e-666b-489a-a26e-a73bce95d73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through hpreact\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "cmp('hpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80972171-7100-4806-a851-d5d417fc1092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([1, 64]) torch.Size([32, 64]) torch.Size([1, 64])\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through bngain -> hpreact = bngain * bnraw + bnbias\n",
    "print(hpreact.shape, bngain.shape, bnraw.shape, bnbias.shape)\n",
    "dbngain = (dhpreact * bnraw).sum(0, keepdims=True)\n",
    "dbnraw = bngain * dhpreact \n",
    "dbnbias = dhpreact.sum(0, keepdims=True)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnbias', dbnbias, bnbias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39d9a5a6-9dde-49bc-9794-e2f402f5f65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64]) torch.Size([32, 64]) torch.Size([32, 64])\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: False | approximate: False | maxdiff: 0.0011646576458588243\n"
     ]
    }
   ],
   "source": [
    "# backprop through batch-norm layer -> bnraw = bndiff * bnvar_inv\n",
    "print(bnvar_inv.shape, dbnraw.shape, bndiff.shape)\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbndiff = dbnraw * bnvar_inv\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bndiff', dbndiff, bndiff) # cause we just backpropagated through one branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea23da56-0ded-40e2-931f-83705a4fc27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through bnvar -> bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "dbnvar = (-0.5 * (bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "cmp('bnvar', dbnvar, bnvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "067ed3b2-ae3b-416e-9a07-d870c765e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([1, 64])\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through bnvar -> bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)\n",
    "print(bndiff.shape, bnvar.shape)\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "cmp('bndiff2', dbndiff2, bndiff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "039b29c1-1bdb-4b03-a0a0-4e2324a4f1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through the second branch of bndiff\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "cmp('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9516f4bb-566f-41a7-b17b-a5fea3cbdbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through -> bndiff = hprebn - bnmeani\n",
    "# print(dbndiff.shape, hprebn.shape, bnmeani.shape)\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6aed25d-7408-485a-8bf5-ce046f720f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "## backprop through -> hprebn = embcat @ W1 + b1\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bdc29d7-ca59-4603-84a5-3ce0d39f7b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30]) torch.Size([32, 3, 10])\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through -> embcat = emb.view(emb.shape[0], -1)\n",
    "print(embcat.shape, emb.shape)\n",
    "demb = dembcat.view(emb.shape)\n",
    "cmp('emb', demb, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "212f949e-5ef5-4bb7-8a82-e86d5c989c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10]) torch.Size([27, 10])\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# backprop through -> emb = C[Xb]\n",
    "print(emb.shape, C.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40670736-7504-47be-aee7-5987bf90d2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.345388412475586 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# before:\n",
    "# forward pass\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# after\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3943f9ca-562f-4f73-874b-91ffb8408547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
     ]
    }
   ],
   "source": [
    "# after: backward pass\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1.0\n",
    "dlogits /= n\n",
    "cmp('dlogits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e31d18e6-f519-4d31-ac82-6ddc3a5133e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27]) torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0670, 0.0919, 0.0181, 0.0463, 0.0190, 0.0798, 0.0239, 0.0352, 0.0188,\n",
       "        0.0327, 0.0348, 0.0393, 0.0369, 0.0288, 0.0334, 0.0142, 0.0093, 0.0193,\n",
       "        0.0176, 0.0541, 0.0488, 0.0210, 0.0260, 0.0748, 0.0630, 0.0241, 0.0220],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is dlogits?\n",
    "print(logits.shape, Yb.shape)\n",
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff1e4b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0670,  0.0919,  0.0181,  0.0463,  0.0190,  0.0798,  0.0239,  0.0352,\n",
       "        -0.9812,  0.0327,  0.0348,  0.0393,  0.0369,  0.0288,  0.0334,  0.0142,\n",
       "         0.0093,  0.0193,  0.0176,  0.0541,  0.0488,  0.0210,  0.0260,  0.0748,\n",
       "         0.0630,  0.0241,  0.0220], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b93b4b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x126cde990>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(dlogits.detach(), cmap='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45e3cf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(3.4094e-05, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# backporp through batchnorm all in one go.\n",
    "# forward pass\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now: \n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True)) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "089ae4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "# calculate dhprebn given dhpreact\n",
    "# now:\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "cmp('dhprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "809e368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.8058\n",
      "  10000/ 200000: 2.1471\n",
      "  20000/ 200000: 2.3857\n",
      "  30000/ 200000: 2.5121\n",
      "  40000/ 200000: 2.0065\n",
      "  50000/ 200000: 2.3200\n",
      "  60000/ 200000: 2.3553\n",
      "  70000/ 200000: 2.0166\n",
      "  80000/ 200000: 2.3658\n",
      "  90000/ 200000: 2.1308\n",
      " 100000/ 200000: 2.0073\n",
      " 110000/ 200000: 2.3660\n",
      " 120000/ 200000: 1.9809\n",
      " 130000/ 200000: 2.4953\n",
      " 140000/ 200000: 2.2772\n",
      " 150000/ 200000: 2.1011\n",
      " 160000/ 200000: 1.9516\n",
      " 170000/ 200000: 1.7972\n",
      " 180000/ 200000: 1.9646\n",
      " 190000/ 200000: 1.9142\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):    \n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "605da29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d93936cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.070317268371582\n",
      "val 2.106351613998413\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c69f701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carmaheam.\n",
      "jhavi.\n",
      "kimrix.\n",
      "taty.\n",
      "skanden.\n",
      "jazhnte.\n",
      "den.\n",
      "arciereni.\n",
      "nellara.\n",
      "chaiha.\n",
      "kaleigh.\n",
      "ham.\n",
      "joce.\n",
      "quintes.\n",
      "lilea.\n",
      "jadbi.\n",
      "waythogiefrynix.\n",
      "kaellissa.\n",
      "med.\n",
      "edi.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
