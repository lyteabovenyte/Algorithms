{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6043635-1605-48e9-876c-bbce4e35d2ac",
   "metadata": {},
   "source": [
    "### introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b84074-fc50-406e-8758-6d21ba38634e",
   "metadata": {},
   "source": [
    "Artificial intelligence, or AI, is concerned with building systems that simulate intelligent\n",
    "behavior. It encompasses a wide range of approaches, including those based on logic,\n",
    "search, and probabilistic reasoning. Machine learning is a subset of AI that learns to\n",
    "make decisions by fitting mathematical models to observed data. This area has seen\n",
    "explosive growth and is now (incorrectly) almost synonymous with the term AI.\n",
    "A deep neural network (or deep network for short) is a type of machine learning\n",
    "model, and the process of fitting these models to data is referred to as deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ebb07-8dd2-4e02-bded-e676ff6e430d",
   "metadata": {},
   "source": [
    "##### supervised learning:\n",
    "a mapping from input data to output predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f7968-ec68-491e-ba2a-be2b9fb113f9",
   "metadata": {},
   "source": [
    "**tabular data**: a fixed-length vector of input which determines the property of the input, the order here is not that important and it has not internal structure. it means that if we change the order and train another model, the ouput we get is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784c1cf-4bba-49be-aa1b-8aac0de5aea4",
   "metadata": {},
   "source": [
    "*models*, which takes an input vector and outputs another vector, are a family of equations mapping the input to the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3435781-1856-4ad0-8fae-57533b099a3c",
   "metadata": {},
   "source": [
    "*deep learning*, which are a particularly useful type of machine\n",
    "learning model. They are equations that can represent an extremely broad family of\n",
    "relationships between input and output, and where it is particularly easy to search\n",
    "through this family to find the relationship that describes the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f512c9-1ab7-4336-bd05-19cf9837a03b",
   "metadata": {},
   "source": [
    "##### unsupervised learning:\n",
    "Constructing a model from input data without corresponding output labels is termed\n",
    "unsupervised learning; the absence of output labels means there can be no “supervision.”\n",
    "Rather than learning a mapping from input to output, the goal is to describe or understand the structure of the data. As was the case for supervised learning, the data may\n",
    "have very different characteristics; it may be discrete or continuous, low-dimensional or\n",
    "high-dimensional, and of constant or variable length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83cde7-af02-43dd-81cf-d28d1fd5c6d8",
   "metadata": {},
   "source": [
    "*Generative unsupervised models*, which learn to synthesize new\n",
    "data examples that are statistically indistinguishable from the training data. Some\n",
    "generative models explicitly describe the *probability distribution* over the input data and\n",
    "here new examples are generated by sampling from this distribution. Others merely learn\n",
    "a mechanism to generate new examples without explicitly describing their distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c5066-d15b-4baa-aef5-3dd01fb2eb43",
   "metadata": {},
   "source": [
    "**latent variable**:\n",
    "Some (but not all) generative models exploit the fact that data can be lower dimensional\n",
    "than the raw number of observed variables suggests. For example, the number of valid\n",
    "and meaningful English sentences is much smaller than the number of strings created by\n",
    "drawing words at random. Similarly, real-world images are a tiny subset of the images\n",
    "that can be created by drawing random red, green, and blue (RGB) values for every\n",
    "pixel. This is because images are generated by physical processes.\n",
    "This leads to the idea that we can describe each data example using a smaller number\n",
    "of underlying *latent variables*. Here, the role of deep learning is to describe the mapping\n",
    "between these latent variables and the data. so, Many generative models use a deep learning model\n",
    "to describe the relationship between a low-dimensional “latent” variable and the\n",
    "observed high-dimensional data. The latent variables have a simple probability\n",
    "distribution by design. Hence, new examples can be generated by sampling from\n",
    "the simple distribution over the latent variables and then using the deep learning\n",
    "model to map the sample to the observed data space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b6cbd-913f-4a6a-8a17-b17a15a80f8c",
   "metadata": {},
   "source": [
    "in other words (GPT answers):\n",
    "Latent variables are hidden variables in a model that are not directly observed but inferred from the data. In deep neural networks, these variables often represent meaningful *underlying structures* or *abstract features* of the input data.\n",
    "Given observed data X, a latent variable model assumes the presence of hidden variables Z such that the probability of X depends on Z:\n",
    "\n",
    "$p(X) = \\int p(X | Z) p(Z) dZ$\n",
    "\n",
    "where:\n",
    "- $Z$ represents latent variables,\n",
    "- $p(X | Z)$ represents the likelihood given the latent structure,\n",
    "- $p(Z)$ represents the prior distribution over the latent space.\n",
    "\n",
    "In *VAE*s, the model learns an encoder $q(Z | X)$ to approximate the posterior distribution $p(Z | X)$, enabling structured latent representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4123c57c-acb4-43c4-832f-43f5d5267b8b",
   "metadata": {},
   "source": [
    "These models lead to new methods for manipulating real data. For example, consider\n",
    "finding the latent variables that underpin two real examples. We can interpolate between\n",
    "these examples by interpolating between their latent representations and mapping the\n",
    "intermediate positions back into the data space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b218eb43-ba58-4af5-b53c-f48dcfba5cb4",
   "metadata": {},
   "source": [
    "Generative models with latent variables can also benefit supervised learning models\n",
    "where the outputs have structure. For example, consider learning to predict\n",
    "the images corresponding to a caption. Rather than directly map the text input to an\n",
    "image, we can learn a relation between latent variables that explain the text and the\n",
    "latent variables that explain the image\n",
    "This has three advantages. \n",
    "- First, we may need fewer text/image pairs to learn this\n",
    "mapping now that the inputs and outputs are lower dimensional.\n",
    "- Second, we are more\n",
    "likely to generate a plausible-looking image; any sensible values of the latent variables\n",
    "should produce something that looks like a plausible example.\n",
    "- Third, if we introduce\n",
    "randomness to either the mapping between the two sets of latent variables or the mapping\n",
    "from the latent variables to the image, then we can generate multiple images that are all\n",
    "described well by the caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2f06d-992a-4cac-a6de-8d95bd63665e",
   "metadata": {},
   "source": [
    "##### Reinforcement learning:\n",
    "This paradigm introduces\n",
    "the idea of an agent which lives in a world and can perform certain actions at each time\n",
    "step. The actions change the state of the system but not necessarily in a deterministic\n",
    "way. Taking an action can also produce rewards, and the goal of reinforcement learning is for the agent to learn to choose actions that lead to high rewards on average.\n",
    "One complication is that the reward may occur some time after the action is taken,\n",
    "so associating a reward with an action is not straightforward. This is known as the\n",
    "*temporal credit assignment problem*. As the agent learns, it must trade off *exploration*\n",
    "and *exploitation* of what it already knows; perhaps the agent has already learned how to\n",
    "receive modest rewards; should it follow this strategy (exploit what it knows), or should\n",
    "it try different actions to see if it can improve (explore other opportunities)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955974d2-86dc-457c-8d70-1fd4aebb813a",
   "metadata": {},
   "source": [
    "It is perhaps not obvious how deep learning fits into the reinforcement learning frame-\n",
    "work. There are several possible approaches, but one technique is to use deep networks\n",
    "to build a mapping from the observed world state to an action. This is known as a\n",
    "*policy network*. In the robot example, the policy network would learn a mapping from\n",
    "its sensor measurements to joint movements. In the chess example, the network would\n",
    "learn a mapping from the current state of the board to the choice of move. so, One way to incorporate\n",
    "deep neural networks into reinforcement learning is to use them to define a mapping from the state to the actions (possible moves). This mapping is known as a *policy*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d81447-9d07-4a94-b3e7-96082126ad0a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
