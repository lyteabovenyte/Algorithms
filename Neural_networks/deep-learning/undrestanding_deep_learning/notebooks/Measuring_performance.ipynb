{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Measuring performance"
      ],
      "metadata": {
        "id": "rtA8SwvOOGob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previous notebooks described neural network models, loss functions, and training algorithms. This one considers how to measure the performance of the trained models.\n",
        "With suï¬€icient capacity (i.e., number of hidden units), a neural network model will often\n",
        "perform perfectly on the training data. However, this does not necessarily mean it will\n",
        "generalize well to new test data.\n",
        "We will see that the test errors have three distinct causes and that their relative\n",
        "contributions depend on (i) the inherent uncertainty in the task, (ii) the amount of\n",
        "training data, and (iii) the choice of model. The latter dependency raises the issue of\n",
        "*hyperparameter* search."
      ],
      "metadata": {
        "id": "zlZ8XBylOMqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. model parameters -> the number of hidden units and the number of hidden layers\n",
        "2. learning algorithm hyperparameters -> learning rate and batch size"
      ],
      "metadata": {
        "id": "FVqzV7-qOnE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three possible sources of error, which are known as *noise*, *bias*, and *variance* respectively"
      ],
      "metadata": {
        "id": "qt_uc6t9tosb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mathematical formulation of test error\n",
        "\n",
        "We now make the notions of noise, bias, and variance mathematically precise. Consider a 1D regression problem where the data generation process has additive noise with variance $\\sigma^2$; we can observe different outputs $y$ for the same input $x$, so for each $x$, there is a distribution $P_{r}(y|x)$ with expected value (mean) $\\mu[x]$:\n",
        "\n",
        "$$\n",
        "\\mu[x] = \\mathbb{E}_y[y|x] = \\int y|x| P_{r}(y|x) dy,\n",
        "$$\n",
        "\n",
        "and fixed noise $\\sigma^2 = \\mathbb{E}_y [(\\mu[x] - y[x])^2]$. Here we have used the notation $y[x]$ to specify that we are considering the output $y$ at a given input position $x$.\n",
        "\n",
        "Now consider a least squares loss between the model prediction $f[x, \\phi]$ at position $x$ and the observed value $y[x]$ at that position:\n",
        "\n",
        "$$\n",
        "L[x] = (f[x, \\phi] - y[x])^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\left((f[x, \\phi] - \\mu[x]) + (\\mu[x] - y[x])\\right)^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "= (f[x, \\phi] - \\mu[x])^2 + 2(f[x, \\phi] - \\mu[x])(\\mu[x] - y[x]) + (\\mu[x] - y[x])^2,\n",
        "$$\n",
        "\n",
        "where we have both added and subtracted the mean $\\mu[x]$ of the underlying function in the second line and have expanded out the squared term in the third line.\n",
        "\n",
        "The underlying function is stochastic, so this loss depends on the particular $y[x]$ we observe. The expected loss is:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}_y [L[x]] = \\mathbb{E}_y \\left[ (f[x, \\phi] - \\mu[x])^2 + 2(f[x, \\phi] - \\mu[x])(\\mu[x] - y[x]) + (\\mu[x] - y[x])^2 \\right]\n",
        "$$\n",
        "\n",
        "$$\n",
        "= (f[x, \\phi] - \\mu[x])^2 + 2(f[x, \\phi] - \\mu[x])(\\mu[x] - \\mathbb{E}_y [y[x]]) + \\mathbb{E}_y [(\\mu[x] - y[x])^2]\n",
        "$$\n",
        "\n",
        "$$\n",
        "= (f[x, \\phi] - \\mu[x])^2 + 2(f[x, \\phi] - \\mu[x]) \\cdot 0 + \\mathbb{E}_y [(\\mu[x] - y[x])^2]\n",
        "$$\n",
        "\n",
        "$$\n",
        "= (f[x, \\phi] - \\mu[x])^2 + \\sigma^2,\n",
        "$$\n",
        "\n",
        "where we have made use of the rules for manipulating expectations. In the second line, we have distributed the expectation operator and removed it from terms with no dependence on $y[x]$, and in the third line, we note that the second term is zero since $\\mathbb{E}_y [y[x]] = \\mu[x]$ by definition. Finally, in the fourth line, we have substituted in the definition of the fixed noise $\\sigma^2$. We can see that the expected loss has been broken down into two terms; the\n",
        "first term is the squared deviation between the model and the true function mean, and\n",
        "the second term is the noise."
      ],
      "metadata": {
        "id": "5vrHWjVO3RiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first term can be further partitioned into bias and variance. The parameters $\\phi$ of the model $f[x, \\phi]$ depend on the training dataset $D = \\{x_i, y_i\\}$, so more properly, we should write $f[x, \\phi[D]]$. The training dataset is a random sample from the data generation process; with a different sample of training data, we would learn different parameter values. The expected model output $f_\\mu[x]$ with respect to all possible datasets $D$ is hence:\n",
        "\n",
        "$$\n",
        "f_\\mu[x] = \\mathbb{E}_D [f[x, \\phi[D]]].\n",
        "$$\n",
        "\n",
        "Returning to the first term of equation 8.3, we add and subtract $f_\\mu[x]$ and expand:\n",
        "\n",
        "$$\n",
        "(f[x, \\phi[D]] - \\mu[x])^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "= (f[x, \\phi[D]] - f_\\mu[x] + (f_\\mu[x] - \\mu[x]))^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "= (f[x, \\phi[D]] - f_\\mu[x])^2 + 2(f[x, \\phi[D]] - f_\\mu[x])(f_\\mu[x] - \\mu[x]) + (f_\\mu[x] - \\mu[x])^2.\n",
        "$$\n",
        "\n",
        "We then take the expectation with respect to the training dataset $D$:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}_D [(f[x, \\phi[D]] - \\mu[x])^2] = \\mathbb{E}_D [(f[x, \\phi[D]] - f_\\mu[x])^2] + (f_\\mu[x] - \\mu[x])^2,\n",
        "$$\n",
        "\n",
        "where we have simplified using similar steps as for equation 8.3. Finally, we substitute this result into equation 8.3:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}_D [\\mathbb{E}_y [L[x]]] = \\mathbb{E}_D [(f[x, \\phi[D]] - f_\\mu[x])^2] + (f_\\mu[x] - \\mu[x])^2 + \\sigma^2\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbb{E}_D [(f[x, \\phi[D]] - f_\\mu[x])^2]+(f_\\mu[x]- \\mu[x])^2 + \\sigma^2\n",
        "$$\n",
        "\n",
        "This equation says that the expected loss after considering the uncertainty in the training data $D$ and the test data $y$ consists of three additive components. The variance is uncertainty in the fitted model due to the particular training dataset we sample. The bias is the systematic deviation of the model from the mean of the function we are modeling. The noise is the inherent uncertainty in the true mapping from input to output. These three sources of error will be present for any task. They combine additively for regression tasks with a least squares loss. However, their interaction can be more complex for other types of problems."
      ],
      "metadata": {
        "id": "zD_SenAZ5MZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reducing variance**:\n",
        "Recall that the variance results from limited noisy training data. Fitting the model\n",
        "to two different training sets results in slightly different parameters. It follows we can\n",
        "reduce the variance by increasing the quantity of training data. This averages out the\n",
        "inherent noise and ensures that the input space is well sampled.\n",
        "the effect of training with 6, 10, and 100 samples. For each dataset\n",
        "size, we show the best-fitting model for three training datasets. With only six samples,\n",
        "the fitted function is quite different each time: the variance is significant. As we increase\n",
        "the number of samples, the fitted models become very similar, and the variance reduces.\n",
        "In general, adding training data almost always improves test performance."
      ],
      "metadata": {
        "id": "8xzKdcPhfq87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reducing bias**:\n",
        "The bias term results from the inability of the model to describe the true underlying\n",
        "function. This suggests that we can reduce this error by making the model more flexible.\n",
        "This is usually done by increasing the model capacity. For neural networks, this means\n",
        "adding more hidden units and/or hidden layers."
      ],
      "metadata": {
        "id": "5tGcahzOhRHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also there exists an unexpected side-effect of increasing the model capacity.\n",
        "For a fixed-size training dataset, the variance term typically increases as the model\n",
        "capacity increases. Consequently, increasing the model capacity does not necessarily\n",
        "reduce the test error. This is known as the bias-variance trade-off."
      ],
      "metadata": {
        "id": "FSSnxQQjhXDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BfzuazlBh3zq"
      }
    }
  ]
}