{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89adcf9a-6db0-4b76-a436-96549711e258",
   "metadata": {},
   "source": [
    "##### linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccfec92-7258-424a-849a-b8accdc61697",
   "metadata": {},
   "source": [
    "When formalizing intuitive concepts, a common approach is to construct a\n",
    "set of objects (symbols) and a set of rules to manipulate these objects. This\n",
    "is known as an *algebra*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c91061-1253-42a8-a025-dfcdda1f4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3fca6d7-af7a-41b6-9cb0-acbff18c99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(np.asmatrix('1 2; 3 4; 5 6'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0bd7305-f728-407a-bfb7-8385328b8984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _ArrayFunctionDispatcher in module numpy:\n",
      "\n",
      "einsum(*operands, out=None, optimize=False, **kwargs)\n",
      "    einsum(subscripts, *operands, out=None, dtype=None, order='K',\n",
      "           casting='safe', optimize=False)\n",
      "\n",
      "    Evaluates the Einstein summation convention on the operands.\n",
      "\n",
      "    Using the Einstein summation convention, many common multi-dimensional,\n",
      "    linear algebraic array operations can be represented in a simple fashion.\n",
      "    In *implicit* mode `einsum` computes these values.\n",
      "\n",
      "    In *explicit* mode, `einsum` provides further flexibility to compute\n",
      "    other array operations that might not be considered classical Einstein\n",
      "    summation operations, by disabling, or forcing summation over specified\n",
      "    subscript labels.\n",
      "\n",
      "    See the notes and examples for clarification.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    subscripts : str\n",
      "        Specifies the subscripts for summation as comma separated list of\n",
      "        subscript labels. An implicit (classical Einstein summation)\n",
      "        calculation is performed unless the explicit indicator '->' is\n",
      "        included as well as subscript labels of the precise output form.\n",
      "    operands : list of array_like\n",
      "        These are the arrays for the operation.\n",
      "    out : ndarray, optional\n",
      "        If provided, the calculation is done into this array.\n",
      "    dtype : {data-type, None}, optional\n",
      "        If provided, forces the calculation to use the data type specified.\n",
      "        Note that you may have to also give a more liberal `casting`\n",
      "        parameter to allow the conversions. Default is None.\n",
      "    order : {'C', 'F', 'A', 'K'}, optional\n",
      "        Controls the memory layout of the output. 'C' means it should\n",
      "        be C contiguous. 'F' means it should be Fortran contiguous,\n",
      "        'A' means it should be 'F' if the inputs are all 'F', 'C' otherwise.\n",
      "        'K' means it should be as close to the layout as the inputs as\n",
      "        is possible, including arbitrarily permuted axes.\n",
      "        Default is 'K'.\n",
      "    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n",
      "        Controls what kind of data casting may occur.  Setting this to\n",
      "        'unsafe' is not recommended, as it can adversely affect accumulations.\n",
      "\n",
      "        * 'no' means the data types should not be cast at all.\n",
      "        * 'equiv' means only byte-order changes are allowed.\n",
      "        * 'safe' means only casts which can preserve values are allowed.\n",
      "        * 'same_kind' means only safe casts or casts within a kind,\n",
      "          like float64 to float32, are allowed.\n",
      "        * 'unsafe' means any data conversions may be done.\n",
      "\n",
      "        Default is 'safe'.\n",
      "    optimize : {False, True, 'greedy', 'optimal'}, optional\n",
      "        Controls if intermediate optimization should occur. No optimization\n",
      "        will occur if False and True will default to the 'greedy' algorithm.\n",
      "        Also accepts an explicit contraction list from the ``np.einsum_path``\n",
      "        function. See ``np.einsum_path`` for more details. Defaults to False.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        The calculation based on the Einstein summation convention.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    einsum_path, dot, inner, outer, tensordot, linalg.multi_dot\n",
      "    einsum:\n",
      "        Similar verbose interface is provided by the\n",
      "        `einops <https://github.com/arogozhnikov/einops>`_ package to cover\n",
      "        additional operations: transpose, reshape/flatten, repeat/tile,\n",
      "        squeeze/unsqueeze and reductions.\n",
      "        The `opt_einsum <https://optimized-einsum.readthedocs.io/en/stable/>`_\n",
      "        optimizes contraction order for einsum-like expressions\n",
      "        in backend-agnostic manner.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The Einstein summation convention can be used to compute\n",
      "    many multi-dimensional, linear algebraic array operations. `einsum`\n",
      "    provides a succinct way of representing these.\n",
      "\n",
      "    A non-exhaustive list of these operations,\n",
      "    which can be computed by `einsum`, is shown below along with examples:\n",
      "\n",
      "    * Trace of an array, :py:func:`numpy.trace`.\n",
      "    * Return a diagonal, :py:func:`numpy.diag`.\n",
      "    * Array axis summations, :py:func:`numpy.sum`.\n",
      "    * Transpositions and permutations, :py:func:`numpy.transpose`.\n",
      "    * Matrix multiplication and dot product, :py:func:`numpy.matmul`\n",
      "        :py:func:`numpy.dot`.\n",
      "    * Vector inner and outer products, :py:func:`numpy.inner`\n",
      "        :py:func:`numpy.outer`.\n",
      "    * Broadcasting, element-wise and scalar multiplication,\n",
      "        :py:func:`numpy.multiply`.\n",
      "    * Tensor contractions, :py:func:`numpy.tensordot`.\n",
      "    * Chained array operations, in efficient calculation order,\n",
      "        :py:func:`numpy.einsum_path`.\n",
      "\n",
      "    The subscripts string is a comma-separated list of subscript labels,\n",
      "    where each label refers to a dimension of the corresponding operand.\n",
      "    Whenever a label is repeated it is summed, so ``np.einsum('i,i', a, b)``\n",
      "    is equivalent to :py:func:`np.inner(a,b) <numpy.inner>`. If a label\n",
      "    appears only once, it is not summed, so ``np.einsum('i', a)``\n",
      "    produces a view of ``a`` with no changes. A further example\n",
      "    ``np.einsum('ij,jk', a, b)`` describes traditional matrix multiplication\n",
      "    and is equivalent to :py:func:`np.matmul(a,b) <numpy.matmul>`.\n",
      "    Repeated subscript labels in one operand take the diagonal.\n",
      "    For example, ``np.einsum('ii', a)`` is equivalent to\n",
      "    :py:func:`np.trace(a) <numpy.trace>`.\n",
      "\n",
      "    In *implicit mode*, the chosen subscripts are important\n",
      "    since the axes of the output are reordered alphabetically.  This\n",
      "    means that ``np.einsum('ij', a)`` doesn't affect a 2D array, while\n",
      "    ``np.einsum('ji', a)`` takes its transpose. Additionally,\n",
      "    ``np.einsum('ij,jk', a, b)`` returns a matrix multiplication, while,\n",
      "    ``np.einsum('ij,jh', a, b)`` returns the transpose of the\n",
      "    multiplication since subscript 'h' precedes subscript 'i'.\n",
      "\n",
      "    In *explicit mode* the output can be directly controlled by\n",
      "    specifying output subscript labels.  This requires the\n",
      "    identifier '->' as well as the list of output subscript labels.\n",
      "    This feature increases the flexibility of the function since\n",
      "    summing can be disabled or forced when required. The call\n",
      "    ``np.einsum('i->', a)`` is like :py:func:`np.sum(a) <numpy.sum>`\n",
      "    if ``a`` is a 1-D array, and ``np.einsum('ii->i', a)``\n",
      "    is like :py:func:`np.diag(a) <numpy.diag>` if ``a`` is a square 2-D array.\n",
      "    The difference is that `einsum` does not allow broadcasting by default.\n",
      "    Additionally ``np.einsum('ij,jh->ih', a, b)`` directly specifies the\n",
      "    order of the output subscript labels and therefore returns matrix\n",
      "    multiplication, unlike the example above in implicit mode.\n",
      "\n",
      "    To enable and control broadcasting, use an ellipsis.  Default\n",
      "    NumPy-style broadcasting is done by adding an ellipsis\n",
      "    to the left of each term, like ``np.einsum('...ii->...i', a)``.\n",
      "    ``np.einsum('...i->...', a)`` is like\n",
      "    :py:func:`np.sum(a, axis=-1) <numpy.sum>` for array ``a`` of any shape.\n",
      "    To take the trace along the first and last axes,\n",
      "    you can do ``np.einsum('i...i', a)``, or to do a matrix-matrix\n",
      "    product with the left-most indices instead of rightmost, one can do\n",
      "    ``np.einsum('ij...,jk...->ik...', a, b)``.\n",
      "\n",
      "    When there is only one operand, no axes are summed, and no output\n",
      "    parameter is provided, a view into the operand is returned instead\n",
      "    of a new array.  Thus, taking the diagonal as ``np.einsum('ii->i', a)``\n",
      "    produces a view (changed in version 1.10.0).\n",
      "\n",
      "    `einsum` also provides an alternative way to provide the subscripts and\n",
      "    operands as ``einsum(op0, sublist0, op1, sublist1, ..., [sublistout])``.\n",
      "    If the output shape is not provided in this format `einsum` will be\n",
      "    calculated in implicit mode, otherwise it will be performed explicitly.\n",
      "    The examples below have corresponding `einsum` calls with the two\n",
      "    parameter methods.\n",
      "\n",
      "    Views returned from einsum are now writeable whenever the input array\n",
      "    is writeable. For example, ``np.einsum('ijk...->kji...', a)`` will now\n",
      "    have the same effect as :py:func:`np.swapaxes(a, 0, 2) <numpy.swapaxes>`\n",
      "    and ``np.einsum('ii->i', a)`` will return a writeable view of the diagonal\n",
      "    of a 2D array.\n",
      "\n",
      "    Added the ``optimize`` argument which will optimize the contraction order\n",
      "    of an einsum expression. For a contraction with three or more operands\n",
      "    this can greatly increase the computational efficiency at the cost of\n",
      "    a larger memory footprint during computation.\n",
      "\n",
      "    Typically a 'greedy' algorithm is applied which empirical tests have shown\n",
      "    returns the optimal path in the majority of cases. In some cases 'optimal'\n",
      "    will return the superlative path through a more expensive, exhaustive\n",
      "    search. For iterative calculations it may be advisable to calculate\n",
      "    the optimal path once and reuse that path by supplying it as an argument.\n",
      "    An example is given below.\n",
      "\n",
      "    See :py:func:`numpy.einsum_path` for more details.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.arange(25).reshape(5,5)\n",
      "    >>> b = np.arange(5)\n",
      "    >>> c = np.arange(6).reshape(2,3)\n",
      "\n",
      "    Trace of a matrix:\n",
      "\n",
      "    >>> np.einsum('ii', a)\n",
      "    60\n",
      "    >>> np.einsum(a, [0,0])\n",
      "    60\n",
      "    >>> np.trace(a)\n",
      "    60\n",
      "\n",
      "    Extract the diagonal (requires explicit form):\n",
      "\n",
      "    >>> np.einsum('ii->i', a)\n",
      "    array([ 0,  6, 12, 18, 24])\n",
      "    >>> np.einsum(a, [0,0], [0])\n",
      "    array([ 0,  6, 12, 18, 24])\n",
      "    >>> np.diag(a)\n",
      "    array([ 0,  6, 12, 18, 24])\n",
      "\n",
      "    Sum over an axis (requires explicit form):\n",
      "\n",
      "    >>> np.einsum('ij->i', a)\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    >>> np.einsum(a, [0,1], [0])\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    >>> np.sum(a, axis=1)\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "\n",
      "    For higher dimensional arrays summing a single axis can be done\n",
      "    with ellipsis:\n",
      "\n",
      "    >>> np.einsum('...j->...', a)\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "    >>> np.einsum(a, [Ellipsis,1], [Ellipsis])\n",
      "    array([ 10,  35,  60,  85, 110])\n",
      "\n",
      "    Compute a matrix transpose, or reorder any number of axes:\n",
      "\n",
      "    >>> np.einsum('ji', c)\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    >>> np.einsum('ij->ji', c)\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    >>> np.einsum(c, [1,0])\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "    >>> np.transpose(c)\n",
      "    array([[0, 3],\n",
      "           [1, 4],\n",
      "           [2, 5]])\n",
      "\n",
      "    Vector inner products:\n",
      "\n",
      "    >>> np.einsum('i,i', b, b)\n",
      "    30\n",
      "    >>> np.einsum(b, [0], b, [0])\n",
      "    30\n",
      "    >>> np.inner(b,b)\n",
      "    30\n",
      "\n",
      "    Matrix vector multiplication:\n",
      "\n",
      "    >>> np.einsum('ij,j', a, b)\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    >>> np.einsum(a, [0,1], b, [1])\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    >>> np.dot(a, b)\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "    >>> np.einsum('...j,j', a, b)\n",
      "    array([ 30,  80, 130, 180, 230])\n",
      "\n",
      "    Broadcasting and scalar multiplication:\n",
      "\n",
      "    >>> np.einsum('..., ...', 3, c)\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    >>> np.einsum(',ij', 3, c)\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    >>> np.einsum(3, [Ellipsis], c, [Ellipsis])\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "    >>> np.multiply(3, c)\n",
      "    array([[ 0,  3,  6],\n",
      "           [ 9, 12, 15]])\n",
      "\n",
      "    Vector outer product:\n",
      "\n",
      "    >>> np.einsum('i,j', np.arange(2)+1, b)\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [0, 2, 4, 6, 8]])\n",
      "    >>> np.einsum(np.arange(2)+1, [0], b, [1])\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [0, 2, 4, 6, 8]])\n",
      "    >>> np.outer(np.arange(2)+1, b)\n",
      "    array([[0, 1, 2, 3, 4],\n",
      "           [0, 2, 4, 6, 8]])\n",
      "\n",
      "    Tensor contraction:\n",
      "\n",
      "    >>> a = np.arange(60.).reshape(3,4,5)\n",
      "    >>> b = np.arange(24.).reshape(4,3,2)\n",
      "    >>> np.einsum('ijk,jil->kl', a, b)\n",
      "    array([[4400., 4730.],\n",
      "           [4532., 4874.],\n",
      "           [4664., 5018.],\n",
      "           [4796., 5162.],\n",
      "           [4928., 5306.]])\n",
      "    >>> np.einsum(a, [0,1,2], b, [1,0,3], [2,3])\n",
      "    array([[4400., 4730.],\n",
      "           [4532., 4874.],\n",
      "           [4664., 5018.],\n",
      "           [4796., 5162.],\n",
      "           [4928., 5306.]])\n",
      "    >>> np.tensordot(a,b, axes=([1,0],[0,1]))\n",
      "    array([[4400., 4730.],\n",
      "           [4532., 4874.],\n",
      "           [4664., 5018.],\n",
      "           [4796., 5162.],\n",
      "           [4928., 5306.]])\n",
      "\n",
      "    Writeable returned arrays (since version 1.10.0):\n",
      "\n",
      "    >>> a = np.zeros((3, 3))\n",
      "    >>> np.einsum('ii->i', a)[:] = 1\n",
      "    >>> a\n",
      "    array([[1., 0., 0.],\n",
      "           [0., 1., 0.],\n",
      "           [0., 0., 1.]])\n",
      "\n",
      "    Example of ellipsis use:\n",
      "\n",
      "    >>> a = np.arange(6).reshape((3,2))\n",
      "    >>> b = np.arange(12).reshape((4,3))\n",
      "    >>> np.einsum('ki,jk->ij', a, b)\n",
      "    array([[10, 28, 46, 64],\n",
      "           [13, 40, 67, 94]])\n",
      "    >>> np.einsum('ki,...k->i...', a, b)\n",
      "    array([[10, 28, 46, 64],\n",
      "           [13, 40, 67, 94]])\n",
      "    >>> np.einsum('k...,jk', a, b)\n",
      "    array([[10, 28, 46, 64],\n",
      "           [13, 40, 67, 94]])\n",
      "\n",
      "    Chained array operations. For more complicated contractions, speed ups\n",
      "    might be achieved by repeatedly computing a 'greedy' path or pre-computing\n",
      "    the 'optimal' path and repeatedly applying it, using an `einsum_path`\n",
      "    insertion (since version 1.12.0). Performance improvements can be\n",
      "    particularly significant with larger arrays:\n",
      "\n",
      "    >>> a = np.ones(64).reshape(2,4,8)\n",
      "\n",
      "    Basic `einsum`: ~1520ms  (benchmarked on 3.1GHz Intel i5.)\n",
      "\n",
      "    >>> for iteration in range(500):\n",
      "    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a)\n",
      "\n",
      "    Sub-optimal `einsum` (due to repeated path calculation time): ~330ms\n",
      "\n",
      "    >>> for iteration in range(500):\n",
      "    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a,\n",
      "    ...         optimize='optimal')\n",
      "\n",
      "    Greedy `einsum` (faster optimal path approximation): ~160ms\n",
      "\n",
      "    >>> for iteration in range(500):\n",
      "    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='greedy')\n",
      "\n",
      "    Optimal `einsum` (best usage pattern in some use cases): ~110ms\n",
      "\n",
      "    >>> path = np.einsum_path('ijk,ilm,njm,nlk,abc->',a,a,a,a,a,\n",
      "    ...     optimize='optimal')[0]\n",
      "    >>> for iteration in range(500):\n",
      "    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize=path)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.einsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f336ddee-00ba-4282-9e15-5a198d4ccd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(25).reshape(5, 5,)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "330cfd98-ad11-4709-ba01-4cb21b9b5efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  35,  60,  85, 110])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ij->i', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31299b47-6319-4b13-9f99-aba07538837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  6, 12, 18, 24])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ii->i', a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a7c91c5-6985-4c1b-862a-6796d744d6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 55, 60, 65, 70])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ij->j', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c610102-869e-49b6-817f-8263f6df20f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14],\n",
       "       [15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "134cb498-b50f-4e0c-9cfa-ff0501705cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.arange(10).reshape(5, 2)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0708cc7d-a8d0-4533-bbc7-96434f296d9a",
   "metadata": {},
   "source": [
    "dot product of two matrices:\n",
    "$c_ij = \\sum_{l=1}^{n} a_{il} b_{lj}$\n",
    "\n",
    "Commonly, the dot\n",
    "product between\n",
    "two vectors a,bis\n",
    "denoted by a⊤b or$\\langle a,b \\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb247efa-7617-4d4e-aa56-9463dfae4a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60,  70],\n",
       "       [160, 195],\n",
       "       [260, 320],\n",
       "       [360, 445],\n",
       "       [460, 570]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc839279-377a-41dd-a555-be756f16fb6b",
   "metadata": {},
   "source": [
    "Matrix multiplication is not defined as an element-wise operation\n",
    "on matrix elements, i.e., $c_{ij} ≠ a_{ij} b_{ij}$ (even if the size of A,B was chosen appropriately). This kind of element-wise multiplication often appears\n",
    "in programming languages when we multiply (multi-dimensional) arrays\n",
    "with each other, and is called a *Hadamard product*.\n",
    "\n",
    "identity matrix:$\\R^{n \\times n}$ is a matrix which has one on diagonal and 0 all over the place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d6e40-6824-4530-9cbc-ea6733211a07",
   "metadata": {},
   "source": [
    "##### representation learning:\n",
    "- autoencoder for example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af618ca8-27d8-4071-9085-28af9c4c5226",
   "metadata": {},
   "source": [
    "##### deep learning.\n",
    "The quintessential example of a deep learning model is the feedforward deep\n",
    "network or multilayer perceptron (MLP). A multilayer perceptron is just a\n",
    "mathematical function mapping some set of input values to output values. The\n",
    "function is formed by composing many simpler functions. We can think of each\n",
    "application of a diﬀerent mathematical function as providing a new representation\n",
    "of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262dd8e-3df3-4c7c-b965-d57864631b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
