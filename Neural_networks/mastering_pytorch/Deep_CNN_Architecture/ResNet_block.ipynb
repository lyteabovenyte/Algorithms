{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet and DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    multiplier = 1\n",
    "    def __init__(self, input_num_planes, num_planes, strd=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channles=input_num_planes, out_channels=num_planes, kernel_size=3, stride=strd, padding=1, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(num_planes)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=num_planes, out_channels=num_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(num_planes)\n",
    "        self.res_connection = nn.Sequential()\n",
    "        # ResNet uses identity shortcuts (i.e., adding the input directly to the output), \n",
    "        # but when downsampling (stride > 1) or changing channels, a direct addition is not possible.\n",
    "        # So, a 1×1 convolution with BatchNorm is used in the shortcut to transform the input appropriately.\n",
    "        if strd > 1 or input_num_planes != self.multiplier * num_planes:\n",
    "            self.res_connection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=input_num_planes, out_channels=self.multiplier * num_planes, kernel_size=1, stride=strd, bias=False),\n",
    "                nn.BatchNorm2d(self.multiplier * num_planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        op = F.relu(self.batch_norm1(self.conv_layer1(x)))\n",
    "        op = self.batch_norm2(self.conv_layer2(op))\n",
    "        op += self.res_connection(x)\n",
    "        op = F.relu(op)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lyteatnyte/Dev/github/Algorithms/venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/lyteatnyte/Dev/github/Algorithms/venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/lyteatnyte/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:47<00:00, 2.16MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DenseNet, or dense networks***, introduced the idea of connecting every convolutional layer with every\n",
    "other layer within what is called a dense block. And every dense block is connected to every other\n",
    "dense block in the overall DenseNet. A dense block is simply a module of two 3x3 densely connected\n",
    "convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, input_num_planes, rate_inc):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm2d(input_num_planes)\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=input_num_planes, out_channels=4*rate_inc, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(4*rate_inc)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=4*rate_inc, out_channels=rate_inc, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        op = self.conv_layer1(F.relu(self.batch_norm1(x)))\n",
    "        op = self.conv_layer2(F.relu(self.batch_norm2(op)))\n",
    "        op = torch.cat((op, x), 1) # concatenate the input and output\n",
    "        return op\n",
    "    \n",
    "class TransBlock(nn.Module):\n",
    "    def __init__(self, input_num_planes, output_num_planes):\n",
    "        super(TransBlock, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm2d(input_num_planes)\n",
    "        self.conv_layer = nn.Conv2d(in_channels=input_num_planes, out_channels=output_num_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        op = self.conv_layer(F.relu(self.batch_norm1(x)))\n",
    "        op = F.avg_pool2d(op, stride=2)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
