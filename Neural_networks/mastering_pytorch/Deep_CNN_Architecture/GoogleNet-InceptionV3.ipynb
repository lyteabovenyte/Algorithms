{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleNet and Inception V3 models\n",
    "***A modulo of parallel convolutional layers***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the drastically new elements introduced by GoogLeNet were the following:\n",
    "- The inception module – a module of several parallel convolutional layers\n",
    "- Using 1x1 convolutions to reduce the number of model parameters\n",
    "- Global average pooling instead of a fully connected layer – reduces overfitting\n",
    "- Using auxiliary classifiers for training – for regularization and gradient stability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=../images/inception-V1.png width=450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=../images/googleNet_arch.png width=450>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, input_planes, n_channels1x1, n_channels3x3red,\n",
    "    n_channels3x3, n_channels5x5red, n_channels5x5, pooling_planes):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        # 1x1 convolution branch\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(input_planes, n_channels1x1, kernel_size=1),\n",
    "            nn.BatchNorm2d(n_channels1x1),\n",
    "        )\n",
    "        # 1x1 followed by 3x3 convolution branch\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(input_planes, n_channels3x3red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n_channels3x3red),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(n_channels3x3red, n_channels3x3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n_channels3x3),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # 1x1 followed by 5x5 convolution branch\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(input_planes, n_channels5x5red, kernel_size=1),\n",
    "            nn.BatchNorm2d(n_channels5x5red),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(n_channels5x5red, n_channels5x5, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n_channels5x5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(n_channels5x5, n_channels5x5, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(n_channels5x5),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # 3x3 pooling followed by 1x1 convolution branch\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(input_planes, pooling_planes, kernel_size=1),\n",
    "            nn.BatchNorm2d(pooling_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, ip):\n",
    "        op1 = self.block1(ip)\n",
    "        op2 = self.block2(ip)\n",
    "        op3 = self.block3(ip)\n",
    "        op4 = self.block4(ip)\n",
    "        return torch.cat([op1, op2, op3, op4], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    " \n",
    "        self.im1 = InceptionModule(192,  64,  96, 128, 16, 32, 32)\n",
    "        self.im2 = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n",
    " \n",
    "        self.max_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    " \n",
    "        self.im3 = InceptionModule(480, 192,  96, 208, 16,  48,  64)\n",
    "        self.im4 = InceptionModule(512, 160, 112, 224, 24,  64,  64)\n",
    "        self.im5 = InceptionModule(512, 128, 128, 256, 24,  64,  64)\n",
    "        self.im6 = InceptionModule(512, 112, 144, 288, 32,  64,  64)\n",
    "        self.im7 = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n",
    " \n",
    "        self.im8 = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.im9 = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n",
    " \n",
    "        self.average_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(4096, 1000)\n",
    " \n",
    "    def forward(self, ip):\n",
    "        op = self.stem(ip)\n",
    "        out = self.im1(op)\n",
    "        out = self.im2(op)\n",
    "        op = self.maxpool(op)\n",
    "        op = self.a4(op)\n",
    "        op = self.b4(op)\n",
    "        op = self.c4(op)\n",
    "        op = self.d4(op)\n",
    "        op = self.e4(op)\n",
    "        op = self.max_pool(op)\n",
    "        op = self.a5(op)\n",
    "        op = self.b5(op)\n",
    "        op = self.avgerage_pool(op)\n",
    "        op = op.view(op.size(0), -1)\n",
    "        op = self.fc(op)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lyteatnyte/Dev/github/Algorithms/venv/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/lyteatnyte/Dev/github/Algorithms/venv/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /Users/lyteatnyte/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
      "100%|██████████| 49.7M/49.7M [01:08<00:00, 766kB/s] \n"
     ]
    }
   ],
   "source": [
    "model = models.googlenet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, we explored Inception models, which have a reduced number of model\n",
    "parameters as the number of layers increased, thanks to the **1x1 convolutions** and **global average pooling**. Furthermore, **auxiliary classifiers** were used to combat the vanishing gradient problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
