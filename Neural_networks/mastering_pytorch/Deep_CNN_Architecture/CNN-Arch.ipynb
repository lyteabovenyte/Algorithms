{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs are among the most powerful machine learning models at solving challenging problems such\n",
    "as image classification, object detection, object segmentation, video processing, natural language pro-\n",
    "cessing, and speech recognition. Their success is attributed to various factors, such as the following:\n",
    "- **Weight sharing**: This makes CNNs parameter-efficient; that is, different features are extracted\n",
    "using the same set of weights or parameters. Features are the high-level representations of\n",
    "input data that the model generates with its parameters.\n",
    "- **Automatic feature extraction**: Multiple feature extraction stages help a CNN to automatically\n",
    "learn feature representations in a dataset.\n",
    "- **Hierarchical learning**: The multi-layered CNN structure helps CNNs to learn low-, mid-, and\n",
    "high-level features.\n",
    "- The ability to explore both spatial and temporal correlations in the data, such as in video-processing tasks.\n",
    "\n",
    "Besides these pre-existing fundamental characteristics, CNNs have advanced over the years with the\n",
    "help of improvements in the following areas:\n",
    "- The use of better activation and loss functions, such as using ReLU to overcome the vanishing\n",
    "gradient problem.\n",
    "- Parameter optimization, such as using an optimizer based on Adaptive Momentum (Adam)\n",
    "instead of simple stochastic gradient descent.\n",
    "- Regularization: Applying dropouts and batch normalization besides L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "besides all of the above, some of the most significant drivers of development in CNNs over the years have been the various\n",
    "architectural innovations:\n",
    "- **Spatial exploration-based CNNs**: The idea behind spatial exploration is using different kernel\n",
    "sizes in order to explore different levels of visual features in input data.\n",
    "- **Depth-based CNNs**: The depth here refers to the depth of the neural network, that is, the num-\n",
    "ber of layers. So, the idea here is to create a CNN model with multiple convolutional layers in\n",
    "order to extract highly complex visual features.\n",
    "- **Width-based CNNs**: Width refers to the number of channels or feature maps in the data or\n",
    "features extracted from the data. So, width-based CNNs are all about increasing the number\n",
    "of feature maps as we go from the input to the output layers.\n",
    "- **Multi-path-based CNNs**: So far, the preceding three types of architectures have had monotonic-\n",
    "ity in connections between layers; that is, direct connections exist only between consecutive\n",
    "layers. Multi-path CNNs brought the idea of making shortcut connections or skip connections\n",
    "between non-consecutive layers. A key advantage of multi-path architectures is a better flow of information across several layers, thanks to the skip connections. This, in turn, also lets the gradient flow back to the input layers without too much dissipation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN development:\n",
    "\n",
    "The ReLU activation function was developed in order to\n",
    "deal with the gradient explosion and decay problem during backpropagation. Non-random initialization\n",
    "of network parameter values proved to be crucial. Max pooling was invented as an effective method\n",
    "for subsampling. GPUs were getting popular for training neural networks, especially CNNs, at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lately, the **channel boosting** technique has proven useful in improving CNN performance. The idea\n",
    "here is to learn novel features and exploit pre-learned features through transfer learning. Most recently,\n",
    "automatically designing new blocks and finding optimal CNN architectures has been a growing trend\n",
    "in CNN research"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
