{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "740f2854",
   "metadata": {},
   "source": [
    "#### Deep Convolutional GANs\n",
    "\n",
    "original [paper](https://arxiv.org/pdf/1511.06434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4edefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    body {\n",
       "        --vscode-font-family: \"Sherif\",;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "    body {\n",
    "        --vscode-font-family: \"Sherif\",;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef3258",
   "metadata": {},
   "source": [
    "in this notebook we'll try to train a DCGAN which is essentially an unsupervised convolution neural network\n",
    "(CNN) model.\n",
    "\n",
    "Both the generator and the discriminator in a DCGAN are purely CNNs with no fully\n",
    "connected layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0040e7",
   "metadata": {},
   "source": [
    "in high-level, For any GAN that is used to generate some kind of real data, the generator usually takes random noise\n",
    "as input and produces an output with the same dimensions as the real data. We call this generated\n",
    "output fake data. The discriminator, on the other hand, works as a binary classifier. It takes in the\n",
    "generated fake data and the real data (one at a time) as input and predicts whether the input data is\n",
    "real or fake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b4095c",
   "metadata": {},
   "source": [
    "<img src=../images/GAN-arch.png width=750 style='display:block; margin:auto;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4aca3",
   "metadata": {},
   "source": [
    "The discriminator network is optimized like any binary classifier, that is, using the binary cross-entropy\n",
    "function. Therefore, the discriminator model’s motivation is to correctly classify real images as real and\n",
    "fake images as fake. The generator network has quite the opposite motivation. the generator loss is expressed as $-log(D(G(x)))$ where x is a random noise inputted into the generator model $G$. $G(x)$ is the generated fake image by the generator model; and $D(G(x))$ is the output probability of\n",
    "the discriminator model, $D$ – that is, the probability of the image being real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c56e27",
   "metadata": {},
   "source": [
    "#### Joint optimizaiton:\n",
    "\n",
    "In execution, these two loss functions are backpropagated alternatively. That is, at every iteration of\n",
    "training, first, the discriminator is frozen, and the parameters of the generator networks are optimized\n",
    "by backpropagating the gradients from the generator loss. Then, the tuned generator is frozen while the discriminator is optimized by backpropagating the gradients from the discriminator loss. This is what we call joint optimization. It has also been referred to as being equivalent to a two-player **Minimax** game in the original GAN paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b6d233",
   "metadata": {},
   "source": [
    "<img src=../images/generator_arch.png width=900 style='display:block; margin:auto;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2008cb7",
   "metadata": {},
   "source": [
    "**Upsampling** in CNNs refers to the process of increasing the spatial resolution of feature maps by inserting additional rows and columns of zeros or by using interpolation methods, such as **bilinear** or\n",
    "**nearest-neighbor interpolation**. This is commonly used in tasks such as image segmentation, where\n",
    "the final output needs to have the same spatial dimensions as the input image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4e958",
   "metadata": {},
   "source": [
    "<img src=../images/discriminator_arch.png width=900 style=\"display:block; margin:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea653a",
   "metadata": {},
   "source": [
    "a stride of 2 at every convolutional layer in this architecture helps to reduce the spatial dimension, while the depth (that is, the number of feature maps) keeps growing. This is a classic\n",
    "CNN-based binary classification architecture being used here to classify between real images and\n",
    "generated fake images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fab81f",
   "metadata": {},
   "source": [
    "from now on, we will build, train, and test a DCGAN model using PyTorch in the form of an exercise.\n",
    "We will use an image dataset to train the model and test how well the generator of the trained DCGAN\n",
    "model performs when producing fake images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==2.2\n",
    "# !pip install torchvision==0.17\n",
    "# !pip install matplotlib==3.5.2\n",
    "!pip install scikit-image==0.19.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dea607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants and hyperparameters\n",
    "num_eps=10\n",
    "bsize=32\n",
    "lrate=0.001\n",
    "# length of the random noise vector, which essentially means that we will draw the \n",
    "# random noise from a 64-dimensional latent space as input to the generator model\n",
    "lat_dimension=64\n",
    "image_sz=64\n",
    "chnls=1\n",
    "logging_intv=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fa074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANGenerator, self).__init__()\n",
    "        self.inp_sz = image_sz // 4\n",
    "        self.lin = nn.Linear(lat_dimension, 128 * self.inp_sz ** 2) # project latent vector to feature map\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.up1 = nn.Upsample(scale_factor=2)\n",
    "        self.cn1 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128, 0.8)\n",
    "        self.rl1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.up2 = nn.Upsample(scale_factor=2)\n",
    "        self.cn2 = nn.Conv2d(128, 64, 3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64, 0.8)\n",
    "        self.rl2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.cn3 = nn.Conv2d(64, chnls, 3, stride=1, padding=1)\n",
    "        self.act = nn.Tanh() # [-1, 1] range for pixel values\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = x.view(x.shape[0], 128, self.inp_sz, self.inp_sz)\n",
    "        x = self.bn1(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.cn1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.rl1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.cn2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.rl2(x)\n",
    "        x = self.cn3(x)\n",
    "        out = self.act(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06923d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GANDiscriminator, self).__init__()\n",
    "\n",
    "        def disc_module(ip_chnls, op_chnls, bnorm=True):\n",
    "            mod = [nn.Conv2d(ip_chnls, op_chnls, 3, 2, 1), \n",
    "                   nn.LeakyReLU(0.2, inplace=True), \n",
    "                   nn.Dropout2d(0.25)]\n",
    "            if bnorm:\n",
    "                mod += [nn.BatchNorm2d(op_chnls, 0.8)]\n",
    "            return mod\n",
    "\n",
    "        self.disc_model = nn.Sequential(\n",
    "            *disc_module(chnls, 16, bnorm=False),\n",
    "            *disc_module(16, 32),\n",
    "            *disc_module(32, 64),\n",
    "            *disc_module(64, 128),\n",
    "        )\n",
    "\n",
    "        # width and height of the down-sized image\n",
    "        ds_size = image_sz // 2 ** 4   # 4 conv layer with down-sampling\n",
    "        self.adverse_lyr = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.disc_model(x)\n",
    "        x = x.view(x.shape[0], -1) # flatten the output of conv layers\n",
    "        out = self.adverse_lyr(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c735961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the discriminator and generator models\n",
    "gen = GANGenerator()\n",
    "disc = GANDiscriminator()\n",
    "# define the loss function\n",
    "adv_loss_func = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85ce74",
   "metadata": {},
   "source": [
    "#### Loading image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb3680",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        root='./data/MNIST/',\n",
    "        train=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize(image_sz, image_sz),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ]),\n",
    "        download=True\n",
    "    ),\n",
    "    batch_size=bsize,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# define optimization schedule for both G and D\n",
    "opt_gen = torch.optim.Adam(gen.parameters(), lr=lrate)\n",
    "opt_disc = torch.optim.Adam(disc.parameters(), lr=lrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ad511a",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./images_mnist\", exist_ok=True)\n",
    "\n",
    "for ep in range(num_eps):\n",
    "    for idx, (images, _) in enumerate(dloader):\n",
    "\n",
    "        # generate ground truths for real and fake images\n",
    "        good_img = Variable(torch.FloatTensor(images.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        bad_img = Variable(torch.FloatTensor(images.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # get a real image\n",
    "        actual_images = Variable(images.type(torch.FloatTensor))\n",
    "\n",
    "        # train the generator model\n",
    "        opt_gen.zero_grad()\n",
    "\n",
    "        # generate a batch of images based on random noise as input\n",
    "        noise = Variable(torch.FloatTensor(np.random.normal(0, 1, (images.shape[0], lat_dimension))))\n",
    "        gen_images = gen(noise)\n",
    "\n",
    "        # generator model optimization - how well can it fool the discriminator\n",
    "        generator_loss = adv_loss_func(disc(gen_images), good_img)\n",
    "        generator_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # train the discriminator model\n",
    "        opt_disc.zero_grad()\n",
    "\n",
    "        # calculate discriminator loss as average of mistakes(losses) in confusing real images as fake and vice versa\n",
    "        actual_image_loss = adv_loss_func(disc(actual_images), good_img)\n",
    "        fake_image_loss = adv_loss_func(disc(gen_images.detach()), bad_img)\n",
    "        discriminator_loss = (actual_image_loss + fake_image_loss) / 2\n",
    "\n",
    "        # discriminator model optimization\n",
    "        discriminator_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        batches_completed = ep * len(dloader) + idx\n",
    "        if batches_completed % logging_intv == 0:\n",
    "            print(f\"epoch number {ep} | batch number {idx} | generator loss = {generator_loss.item()} | discriminator loss = {discriminator_loss.item()}\")\n",
    "            save_image(gen_images.data[:25], f\"images_mnist/{batches_completed}.png\", nrow=5, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
