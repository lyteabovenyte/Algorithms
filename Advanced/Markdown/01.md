- A **greedy algorithm** is a strategy to solve problems that finds the optimal solution by making the locally optimal
choice at each step. It can only find the best solution on a small subclass of problems, but it can also be used
as a heuristic to find approximate (sub-optimal) solutions.

- **NP-complete problems** are a set of problems for which any given solution can be verified quickly (in polyno-
mial time), but there is no known efficient way to locate a solution in the first place. NP-complete problems,
by definition, canâ€™t currently be solved in polynomial time on a classical deterministic machine (for instance,
the RAM model).

- **Dynamic programming** is a strategy for solving complex problems with certain characteristics: a recursive struc-
ture of subproblems, with the result of each subproblem needed multiple times in the computation of the final
solution. The final solution is computed by breaking the problem down into a collection of simpler subprob-
lems, solving each of those subproblems just once, and storing their solutions

- *dynamic programming* is good for optimization problems, and the solution should be in the form of a sequence of decisions.

- [0/1 knapsack problem](https://www.youtube.com/watch?v=nLmhmB6NzcM)

- the idea behind **heap-sort** --> for a given array of elements, first create e heap from them(max_heap or min_heap), and then delete one by one and place them at the end of the array (away from the heap)

- every DS is composed of some part:
  - API --> e.g `top()`, `peek()`, `insert(e, p)`, `remove(e)`, `update(e, p)`
  - invariants --> condition that should always be met
  - Data model --> to host the data, this can be raw chunks of memory, a list, a tree, etc
  - Algorithms --> the logic that are used to update the DS and making sure that the invariants are not violated.
  
- ways to organize data
items in memory so that those items can later be retrieved according to specific **criteria**. The nature of those criteria, together with the way **storage** is used and the
**performance** of the basic operations (adding, removing, and searching elements)
are what determine the characteristics of a data structure.

- **linked-list** are recursive data structures.

- *recursive* --> reasoned about by *induction*

- Binary search trees offer a compromise between the flexibility and performance of
insertions in a linked list and the efficiency of search in an ordered array. All the basic operations (insert, delete, search, minimum and maximum, successor and predecessor)
require examining a number of nodes proportional to the **height** of the tree.

- there are several solutions that allows us to keep BSTs balanced without degrading performance for insert or delete. For instance
  - 2-3 search trees
  - red-black tree
  - B-trees
  - AVL tree

- every abstraction (abstract data structure with some special invariants) need to be build using a concrete data structure,
for example a stack can be implemented using list, an array or in theory even a heap (although a heap is a little sily),
the only trade-off is the performance for some functionality which with some concrete data structure could be faster than the other.

- for a 3-ary tree -> the childrens for index `i` are at `3 * i + 1`, `3 * i + 2` and `3 * (i + 1)` and the parent is at `(i - 1) / 3`. for a d-ary it's the similar apprach.

- 