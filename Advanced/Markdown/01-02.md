- A **greedy algorithm** is a strategy to solve problems that finds the optimal solution by making the locally optimal
choice at each step. It can only find the best solution on a small subclass of problems, but it can also be used
as a heuristic to find approximate (sub-optimal) solutions.

- **NP-complete problems** are a set of problems for which any given solution can be verified quickly (in polyno-
mial time), but there is no known efficient way to locate a solution in the first place. NP-complete problems,
by definition, canâ€™t currently be solved in polynomial time on a classical deterministic machine (for instance,
the RAM model).

- **Dynamic programming** is a strategy for solving complex problems with certain characteristics: a recursive struc-
ture of subproblems, with the result of each subproblem needed multiple times in the computation of the final
solution. The final solution is computed by breaking the problem down into a collection of simpler subprob-
lems, solving each of those subproblems just once, and storing their solutions

- *dynamic programming* is good for optimization problems, and the solution should be in the form of a sequence of decisions.

- [0/1 knapsack problem](https://www.youtube.com/watch?v=nLmhmB6NzcM)

- the idea behind **heap-sort** --> for a given array of elements, first create e heap from them(max_heap or min_heap), and then delete one by one and place them at the end of the array (away from the heap)

- every DS is composed of some part:
  - API --> e.g `top()`, `peek()`, `insert(e, p)`, `remove(e)`, `update(e, p)`
  - invariants --> condition that should always be met
  - Data model --> to host the data, this can be raw chunks of memory, a list, a tree, etc
  - Algorithms --> the logic that are used to update the DS and making sure that the invariants are not violated.
  
- ways to organize data
items in memory so that those items can later be retrieved according to specific **criteria**. The nature of those criteria, together with the way **storage** is used and the
**performance** of the basic operations (adding, removing, and searching elements)
are what determine the characteristics of a data structure.

- **linked-list** are recursive data structures.

- *recursive* --> reasoned about by *induction*

- Binary search trees offer a compromise between the flexibility and performance of
insertions in a linked list and the efficiency of search in an ordered array. All the basic operations (insert, delete, search, minimum and maximum, successor and predecessor)
require examining a number of nodes proportional to the **height** of the tree.

- there are several solutions that allows us to keep BSTs balanced without degrading performance for insert or delete. For instance
  - 2-3 search trees
  - red-black tree
  - B-trees
  - AVL tree

- every abstraction (abstract data structure with some special invariants) need to be build using a concrete data structure,
for example a stack can be implemented using list, an array or in theory even a heap (although a heap is a little sily),
the only trade-off is the performance for some functionality which with some concrete data structure could be faster than the other.

- for a 3-ary tree -> the childrens for index `i` are at `3 * i + 1`, `3 * i + 2` and `3 * (i + 1)` and the parent is at `(i - 1) / 3`. for a d-ary it's the similar apprach.

- insertion sort is designed for linked-list cause it don't need to shift element.

- getting the index of the first_leaf in a Heap with branching factor of D: `((|elements| - 2) / D) + 1`

- worth noting that a heap doesn't reinstate the total ordering like a BST do, it has partial ordering.

- more on [Huffman encoding](https://brilliant.org/wiki/huffman-encoding/)

- in tuning the branchin factor of a heap there are some consideration that needs to be taken into account:
    - the difference is between insert and delete (mainly in `pop()` we delete the root and then get the last value in the heap and put into root and call `pushdown()`, in pushdown we should find the highest priority children, which in case of high branching factor, is time consuming)
    - a 3-way heap is faster than 2-way heaps
    - the trade-off between insert and delete is best balanced with `2 <= D <= 5`
- **profiling** means measuring the running time and possibly the memory consumption of different parts of your code.
- consider best *profiling tools* for your framework.
- a heap is conceptually a tree, but it leverages the *internal array* implementation of that tree to simplify and for the sake of efficiency.
- 